# NTT DATA SÃ¼rdÃ¼rÃ¼lebilirlik RaporlarÄ± RAG Sistemi

Bu proje, NTT DATA'nÄ±n sÃ¼rdÃ¼rÃ¼lebilirlik raporlarÄ± Ã¼zerinde RAG (Retrieval-Augmented Generation) tabanlÄ± sorgulama yapabilen bir sistem geliÅŸtirmektedir. Sistem, PDF raporlarÄ±nÄ± otomatik olarak indirip iÅŸleyerek vektÃ¶r veritabanÄ±na kaydeder ve kullanÄ±cÄ±larÄ±n doÄŸal dil ile sorular sorabilmesini saÄŸlar.

## ğŸ“‹ Ä°Ã§indekiler

- [Ã–zellikler](#Ã–zellikler)
- [Teknoloji Stack](#teknoloji-stack)
- [Kurulum](#kurulum)
- [KullanÄ±m](#kullanÄ±m)
- [API DÃ¶kÃ¼mantasyonu](#api-dÃ¶kÃ¼mantasyonu)
- [KonfigÃ¼rasyon](#konfigÃ¼rasyon)
- [GeliÅŸtirme](#geliÅŸtirme)
- [Deployment](#deployment)
- [Troubleshooting](#troubleshooting)

## ğŸš€ Ã–zellikler

### Core RAG Ã–zellikleri
- **Otomatik PDF Ä°ndirme**: NTT DATA sÃ¼rdÃ¼rÃ¼lebilirlik raporlarÄ±nÄ± otomatik indirme
- **AkÄ±llÄ± Metin Ä°ÅŸleme**: PDF'lerden metin Ã§Ä±karma, temizleme ve chunking
- **GeliÅŸmiÅŸ Embedding**: Sentence-Transformers ile yÃ¼ksek kaliteli embeddings
- **VektÃ¶r VeritabanÄ±**: ChromaDB ile hÄ±zlÄ± ve Ã¶lÃ§eklenebilir vektÃ¶r arama
- **Hibrit Retrieval**: VektÃ¶r benzerliÄŸi + BM25 sparse retrieval kombinasyonu

### GeliÅŸmiÅŸ RAG Teknikleri
- **HyDE (Hypothetical Document Embeddings)**: Daha iyi retrieval iÃ§in hipotez belge oluÅŸturma
- **Multi-Query Retrieval**: Tek soru iÃ§in Ã§oklu sorgu variant'larÄ± oluÅŸturma
- **Ensemble Retrieval**: FarklÄ± retrieval yÃ¶ntemlerini birleÅŸtirme
- **Contextual Compression**: LLM ile irrelevant iÃ§eriÄŸi filtreleme
- **Dynamic Reranking**: SonuÃ§larÄ± baÄŸlama gÃ¶re yeniden sÄ±ralama

### Teknik Ã–zellikler
- **FastAPI**: RESTful API arayÃ¼zÃ¼
- **Asenkron Ä°ÅŸleme**: YÃ¼ksek performanslÄ± concurrent operations
- **Docker Support**: Containerized deployment
- **GCP Integration**: Google Cloud Storage ile backup ve scaling
- **Monitoring**: DetaylÄ± logging ve metrics
- **Health Checks**: Sistem durumu kontrolÃ¼

## ğŸ›  Teknoloji Stack

### Backend & API
- **FastAPI**: Modern, hÄ±zlÄ± web framework
- **Python 3.11**: Temel programlama dili
- **Uvicorn**: ASGI server
- **Pydantic**: Data validation ve serialization

### NLP & ML
- **Sentence-Transformers**: Embedding oluÅŸturma
- **NLTK**: DoÄŸal dil iÅŸleme
- **scikit-learn**: ML utilities
- **NumPy**: Numerical computing

### RAG & LLM
- **LangChain**: RAG pipeline framework
- **Ollama**: Yerel LLM inference
- **Llama 3**: Language model
- **ChromaDB**: VektÃ¶r veritabanÄ±

### PDF Ä°ÅŸleme
- **PyMuPDF**: PDF text extraction
- **Regular Expressions**: Text cleaning

### Cloud & Storage
- **Google Cloud Storage**: Backup ve storage
- **Docker**: Containerization
- **Docker Compose**: Multi-container orchestration

### Monitoring & Testing
- **Loguru**: Advanced logging
- **pytest**: Unit testing
- **HTTPX**: HTTP client for testing

## ğŸ“¦ Kurulum

### Gereksinimler

- Python 3.11+
- Docker & Docker Compose
- Ollama (yerel LLM iÃ§in)
- Google Cloud hesabÄ± (opsiyonel, backup iÃ§in)

### 1. Repository'yi Klonla

```bash
git clone https://github.com/furkan-cyber/ntt-sustainability-rag.git
cd ntt-sustainability-rag
```

### 2. Environment AyarlarÄ±

`.env` dosyasÄ±nÄ± dÃ¼zenle:

```env
# GCP KonfigÃ¼rasyonu
GCP_BUCKET_NAME=ntt-sustainability-reports
GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json

# LLM AyarlarÄ±
LLM_MODEL=llama3
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=2000

# VektÃ¶r VeritabanÄ± AyarlarÄ±
CHROMA_DB_DIR=/app/data/vector_db
COLLECTION_NAME=ntt_sustainability_reports

# FastAPI AyarlarÄ±
FASTAPI_HOST=0.0.0.0
FASTAPI_PORT=8000
FASTAPI_RELOAD=False

# RAG AyarlarÄ±
TOP_K_RETRIEVAL=5
CONFIDENCE_THRESHOLD=0.7
ENABLE_HYDE=True
ENABLE_MULTI_QUERY=True
ENABLE_RERANK=True
```

### 3. Docker ile Kurulum (Ã–nerilen)

```bash
# Servisleri baÅŸlat
docker-compose up -d

# LoglarÄ± kontrol et
docker-compose logs -f app
```

### 4. Manuel Kurulum

```bash
# Virtual environment oluÅŸtur
python -m venv venv
source venv/bin/activate  # Linux/Mac
# veya
venv\Scripts\activate  # Windows

# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt

# NLTK verilerini indir
python -m nltk.downloader punkt stopwords

# Ollama'yÄ± baÅŸlat (ayrÄ± terminal)
ollama serve

# Llama3 modelini yÃ¼kle
ollama pull llama3

# UygulamayÄ± Ã§alÄ±ÅŸtÄ±r
python main.py
```

## ğŸ¯ KullanÄ±m

### API Servisi BaÅŸlatma

Sistem baÅŸlatÄ±ldÄ±ÄŸÄ±nda otomatik olarak:
1. NTT DATA sÃ¼rdÃ¼rÃ¼lebilirlik raporlarÄ±nÄ± indirir
2. PDF'leri iÅŸleyerek vektÃ¶r veritabanÄ±na kaydeder
3. FastAPI server'Ä±nÄ± baÅŸlatÄ±r
4. SaÄŸlÄ±k kontrollerini aktif eder

### Temel Sorgu Ã–rneÄŸi

```bash
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{"question": "NTT DATA'nÄ±n 2023 yÄ±lÄ±ndaki karbon emisyon hedefleri nelerdir?"}'
```

### Python ile KullanÄ±m

```python
import requests

# Soru sor
response = requests.post("http://localhost:8000/ask", json={
    "question": "NTT DATA'nÄ±n sÃ¼rdÃ¼rÃ¼lebilirlik stratejisi hakkÄ±nda bilgi ver"
})

result = response.json()
print(f"Cevap: {result['answer']}")
print(f"Kaynaklar: {result['sources']}")
```

## ğŸ“š API DÃ¶kÃ¼mantasyonu

### Endpoints

#### POST /ask
SÃ¼rdÃ¼rÃ¼lebilirlik raporlarÄ± hakkÄ±nda soru sor.

**Request Body:**
```json
{
  "question": "string"
}
```

**Response:**
```json
{
  "answer": "string",
  "sources": [
    {
      "source": "string",
      "year": "integer",
      "score": "float",
      "method": "string"
    }
  ]
}
```

#### GET /health
Sistem saÄŸlÄ±k durumunu kontrol et.

**Response:**
```json
{
  "status": "healthy",
  "vector_db_count": 1250,
  "last_updated": "2024-01-15T10:30:00"
}
```

### Ã–rnek Sorular

- "NTT DATA'nÄ±n 2023 yÄ±lÄ±ndaki CO2 emisyon hedefleri nelerdir?"
- "Åirketin yeÅŸil enerji kullanÄ±mÄ± hakkÄ±nda bilgi ver"
- "Ã‡alÄ±ÅŸan memnuniyeti ile ilgili metrikler neler?"
- "SÃ¼rdÃ¼rÃ¼lebilirlik alanÄ±ndaki yatÄ±rÄ±mlar hangi alanlara odaklanÄ±yor?"
- "DÃ¶ngÃ¼sel ekonomi yaklaÅŸÄ±mlarÄ± neler?"

## âš™ï¸ KonfigÃ¼rasyon

### Temel Ayarlar

| Parametre | AÃ§Ä±klama | VarsayÄ±lan |
|-----------|----------|------------|
| `CHUNK_SIZE` | Metin chunk boyutu | 1000 |
| `CHUNK_OVERLAP` | Chunk overlap | 200 |
| `EMBEDDING_MODEL` | Embedding model | all-mpnet-base-v2 |
| `TOP_K_RETRIEVAL` | Retrieval sonuÃ§ sayÄ±sÄ± | 5 |
| `CONFIDENCE_THRESHOLD` | Minimum gÃ¼ven eÅŸiÄŸi | 0.7 |

### RAG Teknikleri

| Ã–zellik | AÃ§Ä±klama | VarsayÄ±lan |
|---------|----------|------------|
| `ENABLE_HYDE` | HyDE tekniÄŸi | True |
| `ENABLE_MULTI_QUERY` | Multi-query retrieval | True |
| `ENABLE_RERANK` | Yeniden sÄ±ralama | True |

### LLM AyarlarÄ±

| Parametre | AÃ§Ä±klama | VarsayÄ±lan |
|-----------|----------|------------|
| `LLM_MODEL` | Ollama model adÄ± | llama3 |
| `LLM_TEMPERATURE` | Creativity level | 0.3 |
| `LLM_MAX_TOKENS` | Max token sayÄ±sÄ± | 2000 |

## ğŸ”§ GeliÅŸtirme

### Proje YapÄ±sÄ±

```
ntt-sustainability-rag/
â”œâ”€â”€ main.py                 # Ana uygulama
â”œâ”€â”€ requirements.txt        # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ .env                   # Environment variables
â”œâ”€â”€ Dockerfile             # Docker image
â”œâ”€â”€ docker-compose.yml     # Multi-container setup
â”œâ”€â”€ README.md             # Bu dosya
â”œâ”€â”€ data/                 # Veri dizini
â”‚   â”œâ”€â”€ pdfs/            # Ä°ndirilen PDF'ler
â”‚   â”œâ”€â”€ processed/       # Ä°ÅŸlenmiÅŸ veriler
â”‚   â””â”€â”€ vector_db/       # VektÃ¶r veritabanÄ±
â””â”€â”€ tests/               # Test dosyalarÄ±
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_api.py
    â”œâ”€â”€ test_rag.py
    â””â”€â”€ test_utils.py
```

### SÄ±nÄ±f YapÄ±sÄ±

```python
# Ana modÃ¼ller
Config                    # KonfigÃ¼rasyon yÃ¶netimi
DocumentProcessor        # PDF iÅŸleme
VectorDatabase          # VektÃ¶r veritabanÄ±
LLMService             # LLM etkileÅŸimi
RAGPipeline            # RAG pipeline
APIService             # FastAPI servisi
DataIngestion          # Veri yÃ¼kleme
GCPIntegration         # GCP entegrasyon
Monitoring             # Sistem izleme
```

### Test Ã‡alÄ±ÅŸtÄ±rma

```bash
# TÃ¼m testler
pytest

# Belirli test dosyasÄ±
pytest tests/test_api.py

# Coverage ile
pytest --cov=main

# Verbose output
pytest -v
```

### Yeni Ã–zellik Ekleme

1. **Yeni Retrieval YÃ¶ntemi**:
```python
class CustomRetriever:
    def retrieve(self, query: str) -> List[Dict]:
        # Yeni retrieval logic
        pass
```

2. **RAGPipeline'a Entegrasyon**:
```python
# RAGPipeline.retrieve_documents() metoduna ekle
custom_results = self.custom_retriever.retrieve(question)
retrieval_methods.append(("custom", custom_results))
```

## ğŸš€ Deployment

### Docker Production Deployment

```bash
# Production build
docker build -t ntt-sustainability-rag:latest .

# Production run
docker run -d \
  --name ntt-rag \
  -p 8000:8000 \
  -v $(pwd)/data:/app/data \
  -e GCP_BUCKET_NAME=your-bucket \
  ntt-sustainability-rag:latest
```

### Google Cloud Platform

1. **Container Registry'e Push**:
```bash
# Image'i tag'le
docker tag ntt-sustainability-rag:latest gcr.io/YOUR-PROJECT/ntt-sustainability-rag

# Push et
docker push gcr.io/YOUR-PROJECT/ntt-sustainability-rag
```

2. **Cloud Run Deploy**:
```bash
gcloud run deploy ntt-sustainability-rag \
  --image gcr.io/YOUR-PROJECT/ntt-sustainability-rag \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --memory 2Gi \
  --cpu 2 \
  --timeout 300s
```

### Environment Variables (Production)

```env
# Production ayarlarÄ±
FASTAPI_RELOAD=False
LLM_TEMPERATURE=0.2
CONFIDENCE_THRESHOLD=0.8
ENABLE_RERANK=True

# Scaling ayarlarÄ±
TOP_K_RETRIEVAL=10
CHUNK_SIZE=800
CHUNK_OVERLAP=150
```

## ğŸ” Troubleshooting

### YaygÄ±n Sorunlar

#### 1. Ollama Connection Error
```bash
# Ollama servisini kontrol et
ollama list

# Modeli yeniden yÃ¼kle
ollama pull llama3

# Servisi yeniden baÅŸlat
ollama serve
```

#### 2. ChromaDB Lock Error
```bash
# VektÃ¶r veritabanÄ±nÄ± sÄ±fÄ±rla
rm -rf data/vector_db/*

# UygulamayÄ± yeniden baÅŸlat
python main.py
```

#### 3. Memory Issues
```python
# Config ayarlarÄ±nÄ± optimize et
CHUNK_SIZE = 500
TOP_K_RETRIEVAL = 3
ENABLE_HYDE = False
```

#### 4. PDF Download Failures
```python
# Network timeout'u artÄ±r
response = requests.get(url, timeout=30)

# Retry logic ekle
for attempt in range(3):
    try:
        response = requests.get(url, timeout=10)
        break
    except requests.exceptions.Timeout:
        time.sleep(2)
```

### Debugging

```bash
# Verbose logging
export PYTHONPATH=$PYTHONPATH:.
python -m logging.basicConfig level=DEBUG main.py

# API endpoint test
curl -X GET "http://localhost:8000/health"

# Container logs
docker-compose logs -f app
```

### Performance Tuning

1. **Embedding Optimizasyonu**:
```python
# GPU kullanÄ±mÄ± (varsa)
model = SentenceTransformer('all-mpnet-base-v2', device='cuda')

# Batch processing
embeddings = model.encode(texts, batch_size=32)
```

2. **VektÃ¶r VeritabanÄ± Optimizasyonu**:
```python
# Index parametrelerini ayarla
collection = client.create_collection(
    name="optimized_collection",
    metadata={
        "hnsw:space": "cosine",
        "hnsw:construction_ef": 200,
        "hnsw:M": 16
    }
)
```

## ğŸ“Š Monitoring ve Metrics

### Sistem Metrikleri

- **Response Time**: Ortalama yanÄ±t sÃ¼resi
- **Retrieval Accuracy**: AlÄ±nan belgelerin relevance skoru
- **Token Usage**: LLM token tÃ¼ketimi
- **Vector DB Size**: VektÃ¶r veritabanÄ± boyutu
- **Query Patterns**: SÄ±k sorulan sorular

### Monitoring Endpoints

```bash
# SaÄŸlÄ±k durumu
curl http://localhost:8000/health

# Metrics (future feature)
curl http://localhost:8000/metrics
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Create Pull Request

## ğŸ“„ License

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±nÄ±z.

## ğŸ†˜ Support

- **Issues**: GitHub Issues kullanÄ±n
- **Documentation**: README.md
- **Email**: furkanavcioglu11@gmail.com

## ğŸ”„ Changelog

### v1.0.0
- Ä°lk release
- Temel RAG functionality
- FastAPI integration
- Docker support
- GCP integration

### Future Roadmap
- [ ] Web UI interface
- [ ] Multi-language support
- [ ] Advanced caching
- [ ] Real-time updates
- [ ] Enhanced monitoring
- [ ] A/B testing framework
